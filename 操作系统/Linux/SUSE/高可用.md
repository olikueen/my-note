# 高可用

### 1 安装前准备
#### 1.1 环境介绍
```
发行版本：
        SUSE Linux Enterprise Server 12 (x86_64)
        
HA镜像：
        SLE-12-SP3-HA-DVD-x86_64-GM-CD1.iso

内核版本：
        4.4.73-5-default

服务器信息：
        192.168.44.129 node1
        192.168.44.130 node2

数据盘：
        /dev/sdb
```

#### 1.2 制作HA本地zypper源
```
拷贝HA镜像中软件包，到服务器本地硬盘：
        mkdir -v /mnt/{HA-cdrom,cdrom}
        mount /dev/sr0 /mnt/cdrom/
        cp -r /mnt/cdrom/* /mnt/HA-cdrom/

添加zypper源：
        zypper ar /mnt/HA-cdrom/ HA
        
检查添加结果：
        zypper lr
                # | Alias             | Name              | Enabled | GPG Check | Refresh
                --+-------------------+-------------------+---------+-----------+--------
                1 | HA                | HA                | Yes     | ( p) Yes  | No     
                2 | SLES12-SP3-12.3-0 | SLES12-SP3-12.3-0 | Yes     | (r ) Yes  | No     
```

#### 1.3 集群节点间域名解析
```
vim /etc/hosts
        192.168.44.129  node1
        192.168.44.130  node2
```

#### 1.4 集群节点间时间同步


#### 1.5 集群节点间SSH互信



### 2 部署drbd
#### 2.1 安装drbd
```
zypper in -y drbd drbd-kmp-default drbd-utils yast2-drbd

```

#### 2.2 配置drbd
```
更新 global_common.conf：
        vim /etc/drbd.d/global_common.conf
                startup {
                    # wfc-timeout degr-wfc-timeout outdated-wfc-timeout wait-after-sb
                    wfc-timeout 100;
                    degr-wfc-timeout 120;
                }

增加 data.res：
        vim /etc/drbd.d/data.res
resource data {
    on node1 {
        node-id 0;
        device           /dev/drbd0 minor 0;
        disk             /dev/sdb;
        meta-disk        internal;
        address          ipv4 192.168.44.129:7788;
    }
    on node2 {
        node-id 1;
        device           /dev/drbd0 minor 0;
        disk             /dev/sdb;
        meta-disk        internal;
        address          ipv4 192.168.44.130:7788;
    }
    connection-mesh {
        hosts node1 node2;
    }
    disk {
        resync-rate 100M;
    }
}

检查配置文件语法：
        drbdadm dump all
```
#### 2.4 初始化资源
```
创建资源：
        dd if=/dev/zero of=/dev/sdb bs=1M count=10
        drbdadm create-md data

启动drbd资源：
        drbdadm up data
        
查看启动结果：
        drbd-overview
                0:data/0  Connected(2*) Secondary(2*) Incons/Incons
                
设置drbd主节点，启动drbd主从节点同步：
        drbdadm primary --force data
        
查看同步状态：
        drbdadm status data
    同步中：
    data role:Primary
      disk:UpToDate
      node2 role:Secondary
        replication:SyncSource peer-disk:Inconsistent done:20.30
    同步结束：
    data role:Secondary
      disk:UpToDate
      node1 role:Primary
        peer-disk:UpToDate
                    
创建文件系统：
        mkfs.xfs /dev/drbd0
        
挂载测试：
        mount /dev/drbd0 /mydata

```

#### 2.5 关闭drbd资源
```
为 corosync 和 pacemaker 做准备

drbdadm down data
```

### 3 部署corosync, pacemaker
#### 3.1 安装corosync, pacemaker
```
zypper in -y corosync pacemaker

```

#### 3.2 配置corosync
```
编写 corosync.conf：
        vim /etc/corosync.conf
                totem {
                    version: 2
                    crypto_cipher: aes256
                    crypto_hash: sha1
                    token:          5000
                    token_retransmits_before_loss_const: 10
                    join:           60
                    consensus:      6000
                    vsftype:        none
                    max_messages:   20
                    clear_node_high_bit: yes
                    interface {
                        ringnumber: 0
                        bindnetaddr: 192.168.44.0
                        mcastaddr: 239.255.1.1
                        mcastport: 5405
                        ttl: 1
                    }
                }
                
                logging {
                    fileline: off
                    to_stderr: no
                    to_logfile: yes
                    logfile: /var/log/cluster/corosync.log
                    # Log to the system log daemon. When in doubt, set to yes.
                    to_syslog: no
                    # Log debug messages (very verbose). When in doubt, leave off.
                    debug: on
                    timestamp: on
                    logger_subsys {
                        subsys: QUORUM
                        debug: off
                    }
                }
                
                quorum {
                    provider: corosync_votequorum
                }
                
                nodelist {
                    node {
                        ring0_addr: node1
                        nodeid: 1
                    }
                    node {
                        ring0_addr: node2
                        nodeid: 2
                    }
                }

生成 corosync 认证文件：
        corosync-keygen -l
        
把 corosync.conf 和 authkey 同步到备份节点：
        scp corosync.conf authkey node2:/etc/corosync/
        
修改 corosync.service：
        vim /usr/lib/systemd/system/corosync.service
                StopWhenUnneeded=no
```

#### 3.3 启动corosync, pacemaker
```
修改 corosync.service：
        vim /usr/lib/systemd/system/corosync.service
                StopWhenUnneeded=no

启动服务：
        systemctl start corosync
```


### 4 部署crmsh
#### 4.1 安装crmsh
```
zypper in -y crmsh
```